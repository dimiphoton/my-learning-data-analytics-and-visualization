# Data Analytics & Visualization Portfolio

-----

## Business Intelligence Dashboards (Power BI)

For a data analyst, the **80/20 of Power BI is mastering the data model and creating intuitive, interactive dashboards**. The vast majority of business requests can be answered by properly connecting data sources in the Power Query Editor, creating robust DAX measures for key metrics, and designing reports that allow users to easily filter and explore the data to find their own insights.

My Power BI skills are demonstrated through a **[Comprehensive Sales Performance Dashboard](https://www.google.com/search?q=./PowerBI_Projects/Sales_Dashboard/)**, which tracks KPIs across different regions and product categories.

### ðŸŒ± Beginner

  - [x] Connecting to data sources (Excel, CSV)
  - [x] Building basic charts (Bar, Line, Pie) and tables
  - [x] Creating simple measures using DAX (`SUM`, `AVERAGE`, `COUNT`)
  - [x] Using slicers and filters for basic interactivity
  - [x] Publishing reports to the Power BI service

### ðŸš§ Intermediate

  - [x] Cleaning and transforming data in Power Query Editor
  - [x] Building a relational data model (managing relationships, cardinality)
  - [x] Using more complex DAX functions (`CALCULATE`, `FILTER`, Time Intelligence)
  - [x] Designing report layouts with bookmarks and navigation
  - [x] Implementing row-level security (RLS)

### ðŸš€ Advanced

  - [ ] Advanced data modeling (star schemas, handling many-to-many relationships)
  - [ ] Optimizing performance for large datasets (DAX Studio, Tabular Editor)
  - [ ] Using advanced Power Query features (M language basics)
  - [ ] Creating custom visuals
  - [ ] Incremental refresh and dataflow implementation

-----

## Data Visualization (Tableau)

The **80/20 principle in Tableau revolves around mastering "Show Me," calculated fields, and dashboard actions**. A deep understanding of how Tableau handles different data types allows you to quickly create effective visualizations. Combining these with calculated fields for custom metrics and interactive dashboard actions (Filter, Highlight, URL) covers the majority of use cases for creating powerful, exploratory dashboards.

My proficiency with Tableau is showcased in a **[Global Health Trends Visualization](https://www.google.com/search?q=./Tableau_Projects/Global_Health_Viz/)**, an interactive dashboard exploring key health indicators across the world.

### ðŸŒ± Beginner

  - [x] Connecting to data sources
  - [x] Understanding Dimensions vs. Measures
  - [x] Creating fundamental chart types (bar charts, line charts, maps)
  - [x] Building a simple, single-page dashboard
  - [x] Using filters to slice data

### ðŸš§ Intermediate

  - [x] Creating calculated fields for custom metrics
  - [x] Using parameters to create dynamic reports
  - [x] Building interactive dashboards with actions (Filter, Highlight)
  - [x] Creating groups, sets, and hierarchies
  - [x] Using Level of Detail (LOD) expressions (`FIXED`, `INCLUDE`, `EXCLUDE`)

### ðŸš€ Advanced

  - [ ] Advanced mapping with layers and spatial files
  - [ ] Performance optimization (data extracts, query optimization)
  - [ ] Advanced LOD calculations and table calculations
  - [ ] Building non-standard chart types (e.g., Sankey, Sunburst)
  - [ ] Integrating with Python/R using TabPy/RServe

-----

## Exploratory Data Analysis (Python)

For most data science applications, the **80/20 of Exploratory Data Analysis (EDA) in Python is mastering Pandas for data manipulation and Matplotlib/Seaborn for visualization**. The ability to efficiently load, clean, filter, and aggregate data with Pandas, combined with creating essential plots (histograms, scatter plots, box plots) to understand distributions and relationships, forms the critical foundation of nearly every data science project.

I applied these concepts in an **[Analysis of Customer Churn](https://www.google.com/search?q=./Python_EDA_Projects/Customer_Churn_Analysis.ipynb)**, a Jupyter Notebook that cleans the data, explores key factors, and visualizes the drivers of churn.

### ðŸŒ± Beginner

  - [x] Loading data into a Pandas DataFrame (`pd.read_csv`)
  - [x] Basic DataFrame inspection (`.head()`, `.info()`, `.describe()`)
  - [x] Selecting columns and rows (`[]`, `.loc`, `.iloc`)
  - [x] Handling missing values (`.isnull()`, `.fillna()`)
  - [x] Creating basic plots with Matplotlib or `.plot()` (histograms, line plots)

### ðŸš§ Intermediate

  - [x] Filtering data based on complex conditions
  - [x] Using `.groupby()` for data aggregation
  - [x] Merging and joining DataFrames (`pd.merge`, `.join`)
  - [x] Creating more advanced visualizations with Seaborn (box plots, heatmaps, pair plots)
  - [x] Basic feature engineering (creating new columns from existing ones)

### ðŸš€ Advanced

  - [ ] Advanced data manipulation with multi-level indexing
  - [ ] Using `.apply()` with custom lambda functions for complex transformations
  - [ ] Time-series analysis (resampling, rolling windows)
  - [ ] Creating interactive visualizations (e.g., with Plotly, Bokeh)
  - [ ] Writing functions and classes to create a reusable EDA pipeline
